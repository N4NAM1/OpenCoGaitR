import collections
import torch
import numpy as np
import torchvision.transforms as T
import random

class BaseTransformer(object):
    def __init__(self):
        pass

    def __call__(self, x):
        return x

class Compose(BaseTransformer):
    def __init__(self, transforms):
        self.transforms = transforms

    def __call__(self, x):
        for t in self.transforms:
            x = t(x)
        return x

class ToTensor(BaseTransformer):
    def __call__(self, x):
        return T.functional.to_tensor(x)

class Normalize(BaseTransformer):
    def __init__(self, mean, std):
        self.mean = mean
        self.std = std

    def __call__(self, x):
        return T.functional.normalize(x, self.mean, self.std)

class Resize(BaseTransformer):
    def __init__(self, size, interpolation=T.InterpolationMode.BICUBIC):
        self.size = size
        self.interpolation = interpolation

    def __call__(self, x):
        return T.functional.resize(x, self.size, self.interpolation)

class CLIPNormalize(BaseTransformer):
    """
    è‡ªåŠ¨ä½¿ç”¨ OpenAI CLIP çš„å½’ä¸€åŒ–å‚æ•°
    """
    def __init__(self):
        # CLIP å®˜æ–¹æ ‡å‡†å‚æ•°
        self.mean = [0.48145466, 0.4578275, 0.40821073]
        self.std = [0.26862954, 0.26130258, 0.27577711]

    def __call__(self, x):
        return T.functional.normalize(x, self.mean, self.std)

class CLIPImageProcessor(BaseTransformer):
    """
    ğŸ”¥ æ‡’äººä¸“ç”¨ï¼šä¸€é”®æå®š CLIP çš„æ‰€æœ‰é¢„å¤„ç†
    Resize(224) -> ToTensor -> Normalize
    """
    def __init__(self, size=224):
        self.pipeline = T.Compose([
            T.Resize((size, size), interpolation=T.InterpolationMode.BICUBIC),
            T.ToTensor(),
            CLIPNormalize() # å¤ç”¨ä¸Šé¢çš„ç±»
        ])

    def __call__(self, x):
        return self.pipeline(x)

# æ›´æ–°å·¥å‚å‡½æ•°
def get_transform(transform_cfg):
    if transform_cfg is None: return lambda x: x
    
    tr_list = []
    for tr_s in transform_cfg:
        tr_name = tr_s['type']
        tr_args = tr_s.copy()
        tr_args.pop('type')

        if tr_name == 'Compose': continue
        
        # === æ–°å¢çš„è‡ªåŠ¨ç±» ===
        if tr_name == 'CLIPNormalize':
            tr_list.append(CLIPNormalize())
        elif tr_name == 'CLIPImageProcessor':
            tr_list.append(CLIPImageProcessor(**tr_args))
            
        # === åŸæœ‰çš„åŸºç¡€ç±» ===
        elif tr_name == 'Resize':
            if isinstance(tr_args.get('size'), int):
                tr_args['size'] = (tr_args['size'], tr_args['size'])
            tr_list.append(Resize(**tr_args))
        elif tr_name == 'ToTensor':
            tr_list.append(ToTensor())
        elif tr_name == 'Normalize':
            tr_list.append(Normalize(**tr_args))
        else:
            try:
                Cls = getattr(T, tr_name)
                tr_list.append(Cls(**tr_args))
            except AttributeError:
                print(f"âš ï¸ Warning: Transform {tr_name} not found.")

    return Compose(tr_list)