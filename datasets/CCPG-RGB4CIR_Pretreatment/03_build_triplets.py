import json
import random
import argparse
import os
from collections import defaultdict
from tqdm import tqdm

# ================= è¾…åŠ©å‡½æ•°åŒºåŸŸ =================

def parse_status_attributes(status_str):
    """
    è§£æ CCPG çŠ¶æ€å±æ€§ (ç²—ç²’åº¦é€»è¾‘)
    Args:
        status_str: æ–‡ä»¶å¤¹åç§°, ä¾‹å¦‚ 'U0_D0', 'U1_D0_BG'
    Returns:
        clothing_id (str): æœè£…æ ‡è¯† (å»é™¤BGåçš„å­—ç¬¦ä¸², ç”¨ä½œå”¯ä¸€æœè£…ID)
        has_bag (bool): æ˜¯å¦æœ‰åŒ…
    """
    # ã€ä¿®å¤ã€‘: å¢åŠ å¯¹ None çš„é˜²å¾¡æ€§æ£€æŸ¥ï¼Œé˜²æ­¢ crash
    if status_str is None:
        return "Unknown", False

    has_bag = "BG" in status_str
    # ç²—ç²’åº¦é€»è¾‘ï¼šåªè¦å»é™¤BGåç¼€åçš„å­—ç¬¦ä¸²ä¸åŒï¼Œå°±è§†ä¸ºæœè£…ä¸åŒ
    # ä¾‹å¦‚: U0_D0 vs U1_D0 æ˜¯ä¸åŒçš„è¡£æœ
    clothing_id = status_str.replace("_BG", "").replace("BG", "")
    return clothing_id, has_bag

def get_template_text(templates, key):
    """ä»æ¨¡æ¿åº“ä¸­å®‰å…¨éšæœºè·å–ä¸€æ¡æŒ‡ä»¤æ–‡æœ¬"""
    if key in templates and len(templates[key]) > 0:
        return random.choice(templates[key])
    return ""

def clean_text(text):
    """
    ã€æ–°å¢ã€‘æ¸…ç†æ–‡æœ¬æœ«å°¾çš„æ ‡ç‚¹ç¬¦å·ï¼Œæ–¹ä¾¿æ‹¼æ¥
    """
    if not text: return ""
    return text.strip().rstrip('.!?')

def combine_texts(texts, templates):
    """
    ä½¿ç”¨è¿æ¥è¯æ‹¼æ¥å¤šæ®µæ–‡æœ¬ï¼Œç”¨äºæ„å»ºæ··åˆæˆ–ç»„åˆæŒ‡ä»¤
    """
    # ã€ä¿®æ”¹ã€‘: æ‹¼æ¥å‰å…ˆæ¸…ç†æ‰æ¯ä¸ªå­å¥æœ«å°¾çš„æ ‡ç‚¹
    valid_texts = [clean_text(t) for t in texts if t]
    
    if not valid_texts: return ""
    
    # éšæœºæ‰“ä¹±è¯­åº (ä¾‹å¦‚: å…ˆè¯´è§†è§’è¿˜æ˜¯å…ˆè¯´æ¢è¡£ï¼Œå¢åŠ æ•°æ®å¤šæ ·æ€§)
    random.shuffle(valid_texts)
    
    if len(valid_texts) == 1:
        combined = valid_texts[0]
    else:
        # ã€ä¿®æ”¹ã€‘: æ”¯æŒå¤šæ®µæ–‡æœ¬ä½¿ç”¨ä¸åŒçš„éšæœºè¿æ¥è¯
        combined = valid_texts[0]
        connectors_pool = templates.get("connectors", [" and "])
        
        for i in range(1, len(valid_texts)):
            # æ¯æ¬¡å¾ªç¯éƒ½é‡æ–°éšæœºé€‰ä¸€ä¸ªè¿æ¥è¯
            connector = random.choice(connectors_pool)
            combined += connector + valid_texts[i]
    
    # æ ¼å¼ç®€å•ä¿®æ­£
    combined = combined.strip()
    
    # ç¡®ä¿é¦–å­—æ¯å¤§å†™ (å¦‚æœå¼€å¤´æ˜¯å ä½ç¬¦ {subject} åˆ™ä¸å¤„ç†ï¼Œå¦åˆ™å¤§å†™)
    if len(combined) > 0 and not combined.startswith("{"):
        combined = combined[0].upper() + combined[1:]
    
    # ç¡®ä¿ç»“å°¾æœ‰æ ‡ç‚¹
    if len(combined) > 0 and combined[-1] not in ['.', '!', '?', '}']:
        combined += '.'
        
    return combined

def create_static_caption(pid, status, view):
    """
    ç”Ÿæˆé™æ€æè¿°çš„å ä½ç¬¦ (Ref/Tar å†…éƒ¨ä½¿ç”¨)
    æ³¨æ„ï¼šè¿™é‡Œä¿ç•™äº† {subject} å ä½ç¬¦
    """
    clothing_id, has_bag = parse_status_attributes(status)
    
    # æ„é€ æè¿°éƒ¨ä»¶
    parts = []
    
    # 1. è¡£æœæè¿° (ç²—ç²’åº¦è§„åˆ™)
    if clothing_id == "U0_D0":
        parts.append("in standard outfit")
    else:
        parts.append("wearing different clothes")
        
    # 2. åŒ…æè¿°
    if has_bag:
        parts.append("carrying a bag")
    else:
        parts.append("without a bag")
        
    # 3. è§†è§’æè¿° (Blind View ä½¿ç”¨ Camera ID ä½œä¸ºå ä½)
    view_desc = f"viewed from camera {view}"
    
    # ç»„åˆ: "{subject}, in standard outfit, without a bag, viewed from camera 01."
    desc = "{subject}, " + ", ".join(parts) + ", " + view_desc + "."
    return desc

def generate_instruction_pair(ref_item, tar_item, templates):
    """
    æ ¸å¿ƒæŒ‡ä»¤ç”Ÿæˆé€»è¾‘ï¼šåˆ¤æ–­ Ref å’Œ Tar ä¹‹é—´çš„å·®å¼‚ï¼Œç”Ÿæˆæ­£å‘(fwd)å’Œåå‘(inv)æŒ‡ä»¤
    
    Returns: 
        final_caption (str): æ­£å‘æŒ‡ä»¤
        final_caption_inv (str): åå‘æŒ‡ä»¤
        task_type (str): ä»»åŠ¡ç±»å‹ (viewpoint_change / attribute_change / composite_change)
    """
    # 1. è§£æå±æ€§å·®å¼‚
    ref_cloth, ref_bag = ref_item['parsed_attr']
    tar_cloth, tar_bag = tar_item['parsed_attr']
    
    # --- A. çŠ¶æ€éƒ¨åˆ† (Attribute Instruction) ---
    attr_tasks_fwd = []
    attr_tasks_inv = []
    
    # A1. æ¢è¡£åˆ¤å®š (åªè¦ Clothing ID ä¸åŒå³ä¸ºæ¢è¡£)
    if ref_cloth != tar_cloth:
        attr_tasks_fwd.append("change_cloth")
        attr_tasks_inv.append("change_cloth") # ç²—ç²’åº¦ä¸‹æ¢è¡£æ˜¯å¯¹ç§°æ“ä½œ
        
    # A2. æ¢åŒ…åˆ¤å®š
    if ref_bag != tar_bag:
        if not ref_bag and tar_bag: # åŠ åŒ… (Add Bag)
            attr_tasks_fwd.append("change_bag_add")
            attr_tasks_inv.append("change_bag_remove")
        else: # å»åŒ… (Remove Bag)
            attr_tasks_fwd.append("change_bag_remove")
            attr_tasks_inv.append("change_bag_add")
            
    # ç”ŸæˆçŠ¶æ€æ–‡æœ¬åˆ—è¡¨ (List of strings)
    state_parts_fwd = [get_template_text(templates, t) for t in attr_tasks_fwd]
    state_parts_inv = [get_template_text(templates, t) for t in attr_tasks_inv]

    # --- B. è§†è§’éƒ¨åˆ† (View Instruction) ---
    view_parts_fwd = []
    view_parts_inv = []
    
    # è§†è§’åˆ¤å®š (Blind View: åªè¦ view code ä¸åŒå³ä¸ºå˜è§†è§’)
    has_view_change = ref_item.get('view') != tar_item.get('view')
    if has_view_change:
        v_txt = get_template_text(templates, "change_view")
        view_parts_fwd.append(v_txt)
        view_parts_inv.append(v_txt) # è§†è§’å˜åŒ–æ˜¯å¯¹ç§°æ“ä½œ

    # --- C. ä»»åŠ¡ç±»å‹åˆ¤å®šä¸æœ€ç»ˆæ–‡æœ¬ç»„è£… ---
    final_caption = ""
    final_caption_inv = ""
    task_type = "unknown"

    has_state_change = len(state_parts_fwd) > 0

    # é€»è¾‘æ ¸å¿ƒï¼šåªæœ‰ä¸¤è€…éƒ½å˜æ‰ç®— composite
    if has_state_change and has_view_change:
        task_type = "composite_change"
        # æ‹¼æ¥æ‰€æœ‰éƒ¨åˆ† (å±æ€§ + è§†è§’)
        final_caption = combine_texts(state_parts_fwd + view_parts_fwd, templates)
        final_caption_inv = combine_texts(state_parts_inv + view_parts_inv, templates)
        
    elif has_state_change:
        # åªæœ‰å±æ€§å˜äº† (å¯èƒ½æ˜¯å•çº¯æ¢è¡£ï¼Œå•çº¯æ¢åŒ…ï¼Œæˆ–è€…æ··åˆæ¢è¡£æ¢åŒ…)
        task_type = "attribute_change"
        final_caption = combine_texts(state_parts_fwd, templates)
        final_caption_inv = combine_texts(state_parts_inv, templates)
        
    elif has_view_change:
        # åªæœ‰è§†è§’å˜äº†
        task_type = "viewpoint_change"
        final_caption = combine_texts(view_parts_fwd, templates)
        final_caption_inv = combine_texts(view_parts_inv, templates)
        
    else:
        # æ—¢æ²¡å˜çŠ¶æ€ä¹Ÿæ²¡å˜è§†è§’ (è·³è¿‡)
        return None, None, None

    return final_caption, final_caption_inv, task_type

def create_entry(sid, ref_meta, tar_meta, task_type, caption, caption_inv):
    """
    æ„å»ºç¬¦åˆ CASIA-B CIR æ ¼å¼çš„ JSON æ¡ç›® (åµŒå¥—ç»“æ„)
    """
    # ã€ä¿®å¤ã€‘: å…ˆè§£æçŠ¶æ€ï¼Œå…¼å®¹ 'condition' æˆ– 'status' é”®å
    ref_status = ref_meta.get('condition', ref_meta.get('status'))
    tar_status = tar_meta.get('condition', tar_meta.get('status'))
    
    # ã€ä¿®å¤ã€‘: è·å–é™æ€æè¿°æ—¶ï¼Œä½¿ç”¨å·²ç»è§£æå¥½çš„ ref_statusï¼Œè€Œä¸æ˜¯å†å» get('status')
    ref_static = ref_meta.get('static_caption')
    if not ref_static:
        ref_static = create_static_caption(sid, ref_status, ref_meta.get('view'))
        
    tar_static = tar_meta.get('static_caption')
    if not tar_static:
        tar_static = create_static_caption(sid, tar_status, tar_meta.get('view'))

    return {
        "sid": sid,
        "dataset": "CCPG",
        "task": task_type,
        "caption": caption,         # æ­£å‘æŒ‡ä»¤ (ä¿ç•™ {subject})
        "caption_inv": caption_inv, # åå‘æŒ‡ä»¤ (ä¿ç•™ {subject})
        "ref": {
            "sid": sid,
            "condition": ref_status, # ä½¿ç”¨è§£æå¥½çš„å€¼
            "view": ref_meta.get('view'),
            "seq_path": ref_meta.get('seq_path', ref_meta.get('file_path')),
            "static_caption": ref_static
        },
        "tar": {
            "sid": sid,
            "condition": tar_status, # ä½¿ç”¨è§£æå¥½çš„å€¼
            "view": tar_meta.get('view'),
            "seq_path": tar_meta.get('seq_path', tar_meta.get('file_path')),
            "static_caption": tar_static
        }
    }

# ================= ä¸»é€»è¾‘åŒºåŸŸ =================

def build_ccpg_triplets(args):
    # 1. åŠ è½½å…ƒæ•°æ®å’Œæ¨¡æ¿
    print(f"æ­£åœ¨åŠ è½½å…ƒæ•°æ®: {args.meta_path} ...")
    with open(args.meta_path, 'r') as f:
        meta_data = json.load(f)
    print(f"æ­£åœ¨åŠ è½½æŒ‡ä»¤æ¨¡æ¿: {args.template_path} ...")
    with open(args.template_path, 'r') as f:
        templates = json.load(f)

    # 2. æŒ‰ Subject ID åˆ†ç»„æ•°æ® (é‡å»ºç´¢å¼•)
    pid_groups = defaultdict(list)
    for key, info in meta_data.items():
        # å…¼å®¹ meta æ–‡ä»¶ä¸­çš„ sid æˆ– pid å­—æ®µ
        sid = info.get('sid', info.get('pid'))
        
        # é¢„å…ˆè§£æå±æ€§ï¼Œé¿å…å¾ªç¯ä¸­é‡å¤è®¡ç®—
        # ä¼˜å…ˆå– 'condition'ï¼Œå¦‚æœä¸å­˜åœ¨å– 'status'ï¼Œå†ä¸å­˜åœ¨ç»™ None
        status = info.get('condition', info.get('status'))
        info['parsed_attr'] = parse_status_attributes(status)
        
        pid_groups[sid].append(info)

    # 3. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† ID
    # æŒ‰ç…§ CCPG æƒ¯ä¾‹ï¼Œå‰ N ä¸ª ID é€šå¸¸ç”¨äºè®­ç»ƒ
    all_sids = sorted(list(pid_groups.keys()))
    train_sids = set(all_sids[:args.train_ids_count])
    
    print(f"æ€» ID æ•°: {len(all_sids)}. è®­ç»ƒé›† ID æ•°: {len(train_sids)} (é‡‡æ ·{args.sample_train}/ID), æµ‹è¯•é›† ID æ•°: {len(all_sids)-len(train_sids)} (é‡‡æ ·{args.sample_test}/ID).")
    
    all_triplets = []
    stats = defaultdict(int)

    # 4. éå†æ¯ä¸ª Subject ç”Ÿæˆ Pair
    for sid in tqdm(all_sids, desc="ç”Ÿæˆä¸‰å…ƒç»„"):
        sequences = pid_groups[sid]
        # å¦‚æœä¸€ä¸ª ID ä¸‹åºåˆ—å°‘äº2ä¸ªï¼Œæ— æ³•æ„å»º Pairï¼Œè·³è¿‡
        if len(sequences) < 2: continue

        # ç¡®å®šå½“å‰ ID çš„é‡‡æ ·ä¸Šé™
        is_train = sid in train_sids
        sample_limit = args.sample_train if is_train else args.sample_test
        
        generated_count = 0
        attempts = 0
        # é˜²æ­¢æ­»å¾ªç¯çš„å®‰å…¨é˜ˆå€¼ (æ¯”å¦‚è¯¥ ID ä¸‹åªæœ‰2ä¸ªæ ·æœ¬ï¼Œä¸å¯èƒ½ç”Ÿæˆ400å¯¹)
        max_attempts = sample_limit * 10 

        while generated_count < sample_limit and attempts < max_attempts:
            attempts += 1
            
            # A. éšæœºé€‰æ‹© Reference å’Œ Target
            ref = random.choice(sequences)
            tar = random.choice(sequences)
            
            # æ’é™¤è‡ªå¼•ç”¨ (Source å’Œ Target æ˜¯åŒä¸€ä¸ªåºåˆ—)
            if ref['seq_path'] == tar['seq_path']: continue
            
            # B. ç”ŸæˆæŒ‡ä»¤ä¸ä»»åŠ¡åˆ¤å®š (æ ¸å¿ƒé€»è¾‘)
            caption, caption_inv, task_type = generate_instruction_pair(ref, tar, templates)
            
            # å¦‚æœ caption ä¸º Noneï¼Œè¯´æ˜æ—¢æ²¡å˜å±æ€§ä¹Ÿæ²¡å˜è§†è§’ (ä¾‹å¦‚åŒçŠ¶æ€åŒè§†è§’çš„ä¸åŒåºåˆ—)ï¼Œè·³è¿‡
            if not caption: continue 

            # C. ä¿å­˜ç»“æœ
            entry = create_entry(sid, ref, tar, task_type, caption, caption_inv)
            all_triplets.append(entry)
            
            stats[task_type] += 1
            generated_count += 1

    # 5. ä¿å­˜ç»“æœåˆ°å•ä¸€æ–‡ä»¶
    os.makedirs(os.path.dirname(args.output), exist_ok=True)
    with open(args.output, 'w') as f:
        json.dump(all_triplets, f, indent=4)
    
    print(f"âœ… ç”Ÿæˆå®Œæ¯•! æ€»æ ·æœ¬é‡: {len(all_triplets)}")
    print(f"ğŸ’¾ å·²ä¿å­˜è‡³: {args.output}")
    print("ğŸ“Š ä»»åŠ¡ç±»å‹åˆ†å¸ƒ:", json.dumps(stats, indent=2))

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate CCPG Triplets for GaitCIR Task")
    
    # è¾“å…¥è·¯å¾„
    parser.add_argument('--meta_path', default='datasets/CCPG/meta_ccpg.json', help='Step 02 ç”Ÿæˆçš„å…ƒæ•°æ®è·¯å¾„')
    parser.add_argument('--template_path', default='datasets/CCPG/templates_instruction.json', help='æŒ‡ä»¤æ¨¡æ¿è·¯å¾„')
    
    # è¾“å‡ºè·¯å¾„
    parser.add_argument('--output', default='datasets/CCPG/ccpg_cir_final.json', help='æœ€ç»ˆç”Ÿæˆçš„è®­ç»ƒ/æµ‹è¯•æ•´åˆ JSON')
    
    # é‡‡æ ·ä¸åˆ†å‰²é…ç½®
    parser.add_argument('--train_ids_count', type=int, default=100, help='å‰ N ä¸ª ID åˆ’åˆ†ä¸ºè®­ç»ƒé›† (CCPG é»˜è®¤ 100)')
    parser.add_argument('--sample_train', type=int, default=400, help='è®­ç»ƒé›†æ¯ä¸ª ID é‡‡æ ·çš„ Pair æ•°é‡')
    parser.add_argument('--sample_test', type=int, default=100, help='æµ‹è¯•é›†æ¯ä¸ª ID é‡‡æ ·çš„ Pair æ•°é‡')
    
    args = parser.parse_args()
    
    # æ‰§è¡Œä¸»ç¨‹åº
    build_ccpg_triplets(args)