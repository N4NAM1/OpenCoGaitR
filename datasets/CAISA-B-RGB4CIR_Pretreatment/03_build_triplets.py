import json
import random
import os
from tqdm import tqdm
from collections import defaultdict

# ================= é…ç½®åŒºåŸŸ =================
# è·¯å¾„é…ç½® (è¯·æ ¹æ®ä½ çš„å®žé™…ç›®å½•ç»“æž„è°ƒæ•´)
META_FILE = '../CASIA-B_RGB_JSON/meta_casiab_static.json'
TEMPLATE_FILE = '../CASIA-B_RGB_JSON/templates_instruction.json'
SPLIT_FILE = '../CASIA-B_RGB_JSON/CASIA-B/CASIA-B.json' # æ–°å¢žï¼šåˆ’åˆ†æ–‡ä»¶è·¯å¾„
OUTPUT_TRAIN = '../CASIA-B_RGB_JSON/CASIA-B/casiab_cir_final.json'

# ðŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šåŒºåˆ†è®­ç»ƒå’Œæµ‹è¯•çš„é‡‡æ ·å¼ºåº¦
TRAIN_MAX_PAIRS = 800   # è®­ç»ƒé›†é‡‡æ ·æ·±åº¦ (ä¿æŒé«˜å¯†åº¦)
TEST_MAX_PAIRS = 200    # æµ‹è¯•é›†é‡‡æ ·æ·±åº¦ (é™ä½Žå¯†åº¦ï¼ŒåŠ é€Ÿè¯„ä¼°)

# ===========================================

# === 1. è§†è§’æè¿°æ±  ===
VIEW_TEXT_POOL = {
    "000": ["a front view", "a frontal angle", "a 0-degree view", "a face-to-face view", "a view facing the camera"],
    "018": ["a front-side view", "an oblique angle", "a slight frontal angle", "a front-quarter view"],
    "036": ["a front-side view", "an oblique angle", "a front-quarter view", "a diagonal front view"],
    "054": ["a front-side view", "an oblique angle", "a sharp frontal angle", "a semi-frontal view"],
    "072": ["a side view", "a profile view", "a slight profile", "a near-side view"],
    "090": ["a side view", "a profile view", "a lateral view", "a 90-degree view", "a side-on view"],
    "108": ["a side view", "a profile view", "a 108-degree view", "a past-side view"],
    "126": ["a back-side view", "a rear-oblique view", "a rear-quarter view", "a view walking away at an angle"],
    "144": ["a back-side view", "a rear-oblique view", "a rear-quarter view", "an off-center back view"],
    "162": ["a back-side view", "a rear-oblique view", "a slight rear angle", "an almost back view"],
    "180": ["a back view", "a rear view", "a dorsal view", "a 180-degree view", "a view seen from behind"]
}

# === 2. ç²—ç²’åº¦æ˜ å°„ ===
COARSE_MAP = {
    "000": "front",
    "018": "front-side", "036": "front-side", "054": "front-side",
    "072": "side", "090": "side", "108": "side",
    "126": "back-side", "144": "back-side", "162": "back-side",
    "180": "back"
}

def safe_fill_view(template, view_text):
    return template.replace("{view}", view_text)

def get_instruction(src_item, tgt_item, templates):
    src_c, src_v = src_item['condition'], src_item['view']
    tgt_c, tgt_v = tgt_item['condition'], tgt_item['view']

    # --- A. çŠ¶æ€éƒ¨åˆ† ---
    state_instr = ""
    # æ ¹æ® Condition ç»„åˆé€‰æ‹©å¯¹åº”æ¨¡æ¿
    # å‡è®¾ templates é”®åä¸Ž templates_instruction.json ä¸€è‡´
    if src_c == 'nm' and tgt_c == 'bg': state_instr = random.choice(templates['source_nm_target_bg'])
    elif src_c == 'bg' and tgt_c == 'nm': state_instr = random.choice(templates['source_bg_target_nm'])
    elif src_c == 'nm' and tgt_c == 'cl': state_instr = random.choice(templates['source_nm_target_cl'])
    elif src_c == 'cl' and tgt_c == 'nm': state_instr = random.choice(templates['source_cl_target_nm'])
    elif src_c == 'bg' and tgt_c == 'cl': state_instr = random.choice(templates['source_bg_target_cl'])
    elif src_c == 'cl' and tgt_c == 'bg': state_instr = random.choice(templates['source_cl_target_bg'])
    
    # --- B. è§†è§’éƒ¨åˆ† ---
    view_instr = ""
    src_coarse = COARSE_MAP.get(src_v, src_v)
    tgt_coarse = COARSE_MAP.get(tgt_v, tgt_v)
    
    if src_coarse != tgt_coarse:
        tpl = random.choice(templates['change_view'])
        tgt_angle = tgt_item['view']
        potential_texts = VIEW_TEXT_POOL.get(tgt_angle, [f"{tgt_angle} degree view"]) 
        view_text = random.choice(potential_texts)
        view_instr = safe_fill_view(tpl, view_text)

    # --- C. ç»„è£… ---
    final_caption = ""
    task_type = "unknown"
    
    # Case 1: Composite
    if state_instr and view_instr:
        conn = random.choice(templates['connectors'])
        s_text = state_instr.rstrip('.')
        v_text = view_instr.rstrip('.')
        
        if random.random() > 0.5:
            p2_content = v_text[0].lower() + v_text[1:] if len(v_text) > 0 else ""
            final_caption = f"{s_text}{conn}{p2_content}."
        else:
            p2_content = s_text[0].lower() + s_text[1:] if len(s_text) > 0 else ""
            final_caption = f"{v_text}{conn}{p2_content}."
        task_type = "composite_change"
        
    # Case 2: Attribute Only
    elif state_instr:
        final_caption = state_instr
        task_type = "attribute_change"
        
    # Case 3: Viewpoint Only
    elif view_instr and src_c == tgt_c:
        final_caption = view_instr
        task_type = "viewpoint_change"
    
    return final_caption, task_type

def build():
    print("Loading metadata and templates...")
    try:
        with open(META_FILE, 'r') as f:
            meta_db = json.load(f)
        with open(TEMPLATE_FILE, 'r') as f:
            templates = json.load(f)
        # ðŸ”¥ åŠ è½½åˆ’åˆ†æ–‡ä»¶
        with open(SPLIT_FILE, 'r') as f:
            split_cfg = json.load(f)
    except FileNotFoundError as e:
        print(f"âŒ Error: File not found {e.filename}. Check paths.")
        return

    # è§£æžè®­ç»ƒé›†å’Œæµ‹è¯•é›† ID
    train_ids = set(split_cfg['TRAIN_SET'])
    test_ids = set(split_cfg['TEST_SET'])
    print(f"Split Loaded: {len(train_ids)} Train IDs, {len(test_ids)} Test IDs")

    # 1. é‡å»ºç´¢å¼•
    data_index = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))
    for item in meta_db:
        # è¿™é‡Œè½¬æ¢ sid ä¸ºå­—ç¬¦ä¸²ä»¥é˜²ä¸‡ä¸€
        data_index[str(item['sid'])][item['condition']][item['view']].append(item)
        
    all_triplets = []
    stats = defaultdict(int)
    
    sorted_ids = sorted(data_index.keys())
    print("ðŸš€ Starting triplet generation...")
    
    for sid in tqdm(sorted_ids):
        # ðŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæ ¹æ® ID å†³å®šé‡‡æ ·æ•°é‡
        if sid in train_ids:
            current_max_pairs = TRAIN_MAX_PAIRS
        elif sid in test_ids:
            current_max_pairs = TEST_MAX_PAIRS
        else:
            # å¦‚æžœæœ‰äº› ID ä¸åœ¨åˆ’åˆ†é‡Œï¼Œå¯ä»¥é€‰æ‹©è·³è¿‡æˆ–ç»™ä¸ªé»˜è®¤å€¼
            continue

        conds = data_index[sid]
        
        # æ”¶é›†å¯ç”¨èŠ‚ç‚¹
        nodes = []
        for c in conds:
            for v in conds[c]:
                if len(conds[c][v]) > 0:
                    nodes.append((c, v))
        
        if len(nodes) < 2: continue

        # --- é‡‡æ ·å¾ªçŽ¯ ---
        for _ in range(current_max_pairs):
            src_node = random.choice(nodes)
            tgt_node = random.choice(nodes)
            
            if src_node == tgt_node: continue
            
            src_c, src_v = src_node
            tgt_c, tgt_v = tgt_node
            
            ref_item = random.choice(conds[src_c][src_v])
            tar_item = random.choice(conds[tgt_c][tgt_v])
            
            if ref_item['seq_path'] == tar_item['seq_path']: continue

            # ç”ŸæˆæŒ‡ä»¤
            fwd_caption, task_type = get_instruction(ref_item, tar_item, templates)
            if not fwd_caption: continue

            inv_caption, _ = get_instruction(tar_item, ref_item, templates)

            all_triplets.append({
                "sid": sid,
                "dataset": "CASIA-B",
                "task": task_type,
                "caption": fwd_caption,
                "caption_inv": inv_caption,
                "ref": ref_item,
                "tar": tar_item,
                # å¯é€‰ï¼šæ ‡è®°æ˜¯è®­ç»ƒè¿˜æ˜¯æµ‹è¯•æ ·æœ¬ï¼Œæ–¹ä¾¿åŽç»­ debug
                "split": "train" if sid in train_ids else "test"
            })
            stats[task_type] += 1

    # ä¿å­˜ç»“æžœ
    os.makedirs(os.path.dirname(OUTPUT_TRAIN), exist_ok=True)
    with open(OUTPUT_TRAIN, 'w') as f:
        json.dump(all_triplets, f, indent=4)
    
    print(f"âœ… Done! Total samples: {len(all_triplets)}")
    print(f"   Train Sampling: {TRAIN_MAX_PAIRS}/ID")
    print(f"   Test Sampling : {TEST_MAX_PAIRS}/ID")
    print("ðŸ“Š Task Distribution:", dict(stats))

if __name__ == '__main__':
    build()