import os
import json
import pickle
import numpy as np
import torch
from torch.utils.data import Dataset
from PIL import Image

# å¼•å…¥æˆ‘ä»¬ä¹‹å‰å†™å¥½çš„ transform æ¨¡å—
from .transform import get_transform

class GaitCIRDataset(Dataset):
    def __init__(self, data_cfg, mode='train'):       
        self.mode = mode
        self.data_cfg = data_cfg
        
        # === 1. åŸºæœ¬é…ç½® ===
        self.dataset_name = data_cfg['dataset_name'].upper()
        self.dataset_root = data_cfg['dataset_root']
        self.use_features = data_cfg.get('use_features', False)
        self.feature_root = data_cfg.get('feature_root', self.dataset_root)
        self.rgb_subfolder = "RGB" 
        
        # === 2. é‡‡æ ·é…ç½® ===
        if mode == 'train':
            self.max_frames = data_cfg.get('train_max_frames', 30)
        else:
            self.max_frames = data_cfg.get('test_max_frames', 'all')
            
        self.subject_token = "the person" 

        # === 3. åˆå§‹åŒ– Transform ===
        tr_cfg = data_cfg.get('transform', [])
        self.transform = get_transform(tr_cfg)
        print(f"[{mode.upper()}] Transform Initialized.")

        # === 4. åŠ è½½ç´¢å¼•æ–‡ä»¶ ===
        json_path = data_cfg['train_json']
        print(f"[{mode.upper()}] Loading Index: {json_path}")
        with open(json_path, 'r') as f:
            all_data = json.load(f)
            
        # === 5. æ•°æ®åˆ’åˆ† ===
        split_config_path = data_cfg.get('split_config', None)
        if split_config_path and os.path.exists(split_config_path):
            with open(split_config_path, 'r') as f:
                split_cfg = json.load(f)
            subset_key = 'TRAIN_SET' if mode == 'train' else 'TEST_SET'
            allowed_ids = set(split_cfg[subset_key])
            self.data = [item for item in all_data if str(item['sid']) in allowed_ids]
            print(f"âœ… Filter Applied ({subset_key}): {len(all_data)} -> {len(self.data)} triplets kept.")
        else:
            self.data = all_data

    def _load_sequence(self, rel_seq_path):
        """ 
        è¯»å–å›¾åƒåºåˆ— (å†…å­˜ä¼˜åŒ–ç‰ˆ)
        ç­–ç•¥ï¼šå…ˆé‡‡æ ·ç´¢å¼•ï¼Œå†è¯»å–æ–‡ä»¶ã€‚é¿å…å…¨é‡åŠ è½½ã€‚
        """
        # æ„å»ºè·¯å¾„
        base_path = os.path.join(self.dataset_root, self.rgb_subfolder, rel_seq_path)
        pkl_path = base_path if base_path.endswith('.pkl') else base_path + ".pkl"
        dir_path = base_path

        seq_data = None
        is_raw_images = False
        
        # --- ç­–ç•¥ A: PKL (é€šå¸¸æ— æ³•é¿å…å…¨é‡åŠ è½½ï¼Œé™¤é pickle ç»“æ„ç‰¹æ®Š) ---
        if os.path.exists(pkl_path):
            try:
                with open(pkl_path, 'rb') as f:
                    seq_data = pickle.load(f)
            except Exception as e:
                print(f"âš ï¸ [Pickle Error] {pkl_path}: {e}")

        # --- ç­–ç•¥ B: æ–‡ä»¶å¤¹ (Raw Images) - å†…å­˜ä¼˜åŒ–çš„å…³é”® ---
        elif os.path.isdir(dir_path):
            # 1. å…ˆåªè¯»æ–‡ä»¶åï¼Œä¸è¯»å›¾ç‰‡å†…å®¹ï¼
            imgs = sorted([f for f in os.listdir(dir_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
            if len(imgs) > 0:
                seq_data = imgs  # æ­¤æ—¶ seq_data åªæ˜¯æ–‡ä»¶ååˆ—è¡¨ï¼Œå†…å­˜å ç”¨æå°
                is_raw_images = True

        if seq_data is None or len(seq_data) == 0:
            return None

        total = len(seq_data)
        
        # --- é‡‡æ ·é€»è¾‘ (Sample First) ---
        if self.mode == 'train':
            frames_to_sample = self.max_frames if isinstance(self.max_frames, int) else 30
            replace = total < frames_to_sample
            indices = sorted(np.random.choice(total, frames_to_sample, replace=replace))
        else:
            if self.max_frames == "all" or self.max_frames is all: 
                indices = np.arange(total)
            else:
                frames_to_sample = int(self.max_frames)
                indices = np.linspace(0, total - 1, frames_to_sample, dtype=int)

        # --- åŠ è½½ä¸ Transform (Load Later) ---
        final_imgs = []
        
        for idx in indices:
            # åˆ†æ”¯ 1: åŸå›¾æ¨¡å¼ (æŒ‰éœ€è¯»å–ï¼Œçœå†…å­˜ï¼)
            if is_raw_images:
                img_name = seq_data[idx] # seq_data æ˜¯æ–‡ä»¶ååˆ—è¡¨
                img_path = os.path.join(dir_path, img_name)
                try:
                    # ç›´æ¥ç”¨ PIL è¯»å–ï¼Œé¿å… CV2 è½¬æ¢å¼€é”€
                    img = Image.open(img_path).convert('RGB')
                except:
                    # åå›¾å…œåº•ï¼šç”Ÿæˆé»‘å›¾
                    img = Image.new('RGB', (224, 224))
            
            # åˆ†æ”¯ 2: PKL æ¨¡å¼ (seq_data å·²ç»æ˜¯åŠ è½½å¥½çš„å¯¹è±¡åˆ—è¡¨)
            else:
                img = seq_data[idx]
                if isinstance(img, np.ndarray):
                    if img.ndim == 3 and img.shape[0] == 3: img = img.transpose(1, 2, 0)
                    elif img.ndim == 3 and img.shape[0] == 1: img = img.squeeze(0)
                    if img.dtype != np.uint8: img = img.astype(np.uint8)
                    img = Image.fromarray(img)
            
            # åº”ç”¨ Transform
            if self.transform:
                img = self.transform(img)
            
            final_imgs.append(img)

        if len(final_imgs) > 0 and isinstance(final_imgs[0], torch.Tensor):
            return torch.stack(final_imgs)
        return final_imgs

    def _load_features(self, rel_seq_path):
        # ... (Feature æ¨¡å¼ä¿æŒä¸å˜ï¼Œå› ä¸ºå®ƒæœ¬æ¥å°±å¾ˆå°) ...
        path = os.path.join(self.feature_root, rel_seq_path + ".pt")
        if not os.path.exists(path): 
            path = os.path.join(self.feature_root, rel_seq_path)
        if not os.path.exists(path): return None
        data = torch.load(path, map_location='cpu')
        total = data.size(0)
        if total == 0: return None
        
        if self.mode == 'train':
            frames_to_sample = self.max_frames if isinstance(self.max_frames, int) else 30
            replace = total < frames_to_sample
            indices = sorted(np.random.choice(total, frames_to_sample, replace=replace))
        else:
            if self.max_frames == "all" or self.max_frames is all: indices = np.arange(total)
            else: frames_to_sample = int(self.max_frames); indices = np.linspace(0, total - 1, frames_to_sample, dtype=int)
        return data[indices]

    def __getitem__(self, idx):
        retries = 0
        max_retries = 10
        while True:
            if retries > max_retries:
                item = self.data[idx]
                print(f"ğŸ’€ [Fatal] Failed: {item['sid']} - {item['ref']['seq_path']}")
                raise RuntimeError(f"âŒ Max retries exceeded")

            item = self.data[idx]
            try:
                if self.use_features:
                    ref_out = self._load_features(item['ref']['seq_path'])
                    tar_out = self._load_features(item['tar']['seq_path'])
                else:
                    ref_out = self._load_sequence(item['ref']['seq_path'])
                    tar_out = self._load_sequence(item['tar']['seq_path'])

                if ref_out is None or tar_out is None:
                    raise ValueError(f"Data missing")

                caption = item['caption'].replace("{subject}", self.subject_token)
                caption_inv = item.get('caption_inv', "").replace("{subject}", self.subject_token)
                
                return ref_out, tar_out, caption, caption_inv, item['task'], {
                    "sid": str(item['sid']), 

                    # æ˜¾å¼é‡å‘½åä¸ºè¯„ä¼°å™¨éœ€è¦çš„ Key
                    "tar_cond": str(item['tar']['condition']), 
                    "tar_view": str(item['tar']['view']),

                    # æ–°å¢ Reference ä¿¡æ¯
                    "ref_cond": str(item['ref']['condition']),
                    "ref_view": str(item['ref']['view']),

                }
            except Exception:
                if self.mode == 'train': idx = np.random.randint(len(self.data)); retries += 1
                else: raise 
    
    def __len__(self): return len(self.data)