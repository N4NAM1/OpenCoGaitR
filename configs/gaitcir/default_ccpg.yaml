# æ•°æ®é…ç½®
data_cfg:
  dataset_name: CCPG
  # ğŸ”¥ è¿™é‡Œå¡«ä½ çš„çˆ¶çº§ç›®å½•ï¼Œä»£ç ä¼šè‡ªåŠ¨æ‹¼ /RGB/
  dataset_root: /root/autodl-tmp/CCPG_Processed
  
  # ç´¢å¼•æ–‡ä»¶
  train_json: datasets/CCPG_RGB_JSON/CCPG/ccpg_cir_final.json
  split_config: datasets/CCPG_RGB_JSON/CCPG/CCPG.json
  
  # æ¨¡å¼
  use_features: false
  # feature_root: "/root/autodl-tmp/CASIA-B-Processed/CLIP_feature_Unmasked"
  
  # çº¿ç¨‹æ•°
  num_workers: 8

  # é¢„å¤„ç† (ä½¿ç”¨æˆ‘ä»¬åœ¨ transform.py é‡Œå†™çš„ç±»)
  transform:
    - type: CLIPImageProcessor
      size: 224

# æ¨¡å‹é…ç½®
model_cfg:
  model: GaitCIRModel  # å¯¹åº” gaitcir.py é‡Œçš„ç±»å
  backbone: openai/clip-vit-base-patch32
  
  # Combiner å‚æ•°
  projection_dim: 512
  hidden_dim: 2048
  loss_alpha: 0.5

# ä¼˜åŒ–å™¨
optimizer_cfg:
  solver: AdamW
  lr: 1.0e-4
  weight_decay: 0.01

# è°ƒåº¦å™¨
scheduler_cfg:
  scheduler: cosine
  warmup_steps: 100

# è®­ç»ƒå¼•æ“é…ç½®
trainer_cfg:
  save_name: GaitCIR_Baseline
# âœ… å¿…é¡»ä¿®æ”¹ä¸º (CLIP åªèƒ½è·‘ FP32)
  enable_float16: false
  
  # å»ºè®®åŒæ—¶å…³é—­è¿™ä¸ªä»¥èŠ‚çœæ˜¾å­˜
  find_unused_parameters: false
  epochs: 60
  enable_float16: true
  log_iter: 10000
  save_iter: 10000
  total_iter: 40000
  with_test: false  # è®­ç»ƒä¸­é€”æ˜¯å¦æµ‹è¯•
  sampler:
    batch_size: 64           # è®­ç»ƒæ—¶çš„ Batch Size
    train_max_frames: 16     # è®­ç»ƒæ—¶çš„å¸§æ•°
    type: StandardSampler    # å ä½ç¬¦ï¼Œè¡¨ç¤ºä½¿ç”¨æ ‡å‡† Mini-Batch é‡‡æ ·
  
  # DDP å‚æ•°
  sync_BN: false
  fix_BN: false
  find_unused_parameters: true

# è¯„ä¼°é…ç½®
evaluator_cfg:
  sampler:
      batch_size: 32           # æµ‹è¯•æ—¶çš„ Batch Size
      test_max_frames: all     # è¯„ä¼°æ—¶çš„å¸§æ•° (å¦‚æœæœ‰)
      type: InferenceSampler   # å ä½ç¬¦